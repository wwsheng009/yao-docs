# Seed 数据导入

Seed 模块提供了便捷的数据导入功能，支持将 CSV、Excel(XLS/XLSX)、JSON 和 Yao(JSONC) 格式的数据文件导入到指定模型中。

## 功能特性

- **多格式支持**：CSV、XLS、XLSX、JSON、Yao(JSONC)
- **批量导入**：高效分批处理大数据量
- **灵活的重复处理**：忽略、更新、报错、终止四种策略
- **自动类型转换**：支持 JSON 字段、布尔字段的智能解析
- **错误追踪**：详细的错误报告，包含行号和数据内容

## 使用方法

### 基本语法

```javascript
// 在脚本中调用
Process('seeds.import', filename, modelName, options);
```

**参数说明：**

- `filename` (string): 数据文件路径，相对于 `seed` 根目录
- `modelName` (string): 目标模型名称
- `options` (object, 可选): 导入选项配置

### 导入选项 (ImportOption)

| 参数         | 类型   | 默认值   | 说明                   |
| ------------ | ------ | -------- | ---------------------- |
| `chunk_size` | int    | 500      | 每批处理的数据行数     |
| `duplicate`  | string | "ignore" | 重复数据处理策略       |
| `mode`       | string | "batch"  | 导入模式（批量或单条） |

### 重复数据处理策略 (DuplicateMode)

| 策略     | 说明                           |
| -------- | ------------------------------ |
| `ignore` | 忽略重复数据，继续处理其他记录 |
| `update` | 更新已存在的记录               |
| `error`  | 遇到重复时记录错误但不中断     |
| `abort`  | 遇到重复时立即终止导入         |

### 导入模式 (ImportMode)

| 模式    | 说明                                                         |
| ------- | ------------------------------------------------------------ |
| `batch` | 批量模式，使用 `Model.Insert` 批量插入，性能更高             |
| `each`  | 单条模式，使用 `Model.Create` 逐条插入，支持更精细的错误处理 |

## 使用示例

### 1. 导入 CSV 文件

```javascript
// 基本导入，使用默认选项
Process('seeds.import', 'users.csv', 'user');

// 指定选项
Process('seeds.import', 'users.csv', 'user', {
  chunk_size: 1000,
  duplicate: 'update',
  mode: 'each'
});
```

**CSV 格式要求：**

- 第一行为字段名称，必须与模型列名匹配
- 数据行从第二行开始
- 支持字段数量可变（通过 `FieldsPerRecord = -1`）
- 字符串中包含逗号需要用引号包裹

**CSV 示例：**

```csv
id,name,email,active,metadata
1,张三,zhangsan@example.com,true,"{\"role\":\"admin\"}"
2,李四,lisi@example.com,false,"{\"role\":\"user\"}"
```

### 2. 导入 Excel 文件

```javascript
// 导入 XLSX 文件
Process('seeds.import', 'products.xlsx', 'product');

// 导入 XLS 文件
Process('seeds.import', 'data.xls', 'order', {
  duplicate: 'ignore'
});
```

**Excel 格式要求：**

- 使用活动工作表（ActiveSheet）
- 第一行为字段名称
- 数据从第二行开始
- 空行会被自动跳过

**Excel 示例：**

| id  | name  | price  | description |
| --- | ----- | ------ | ----------- |
| 1   | 商品A | 99.99  | 优质商品    |
| 2   | 商品B | 149.99 | 热销商品    |

### 3. 导入 JSON 文件

```javascript
// 导入 JSON 数组
Process('seeds.import', 'data.json', 'article', {
  duplicate: 'update',
  mode: 'batch'
});
```

**JSON 格式要求：**

- 必须是对象数组格式
- 对象的 key 必须与模型列名匹配
- 仅包含模型中存在的字段
- 自动排除自动生成的字段（created_at、updated_at 等）

**JSON 示例：**

```json
[
  {
    "id": 1,
    "title": "文章标题1",
    "content": "文章内容1",
    "status": "published"
  },
  {
    "id": 2,
    "title": "文章标题2",
    "content": "文章内容2",
    "status": "draft"
  }
]
```

### 4. 导入 Yao 文件

```javascript
// 导入 Yao (JSONC) 文件
Process('seeds.import', 'articles.yao', 'article', {
  duplicate: 'abort'
});
```

**Yao 文件格式要求：**

- 支持 JSONC 格式（带注释的 JSON）
- 数据格式与 JSON 相同
- 使用 `.yao` 或 `.jsonc` 扩展名

**Yao 文件示例：**

```jsonc
[
  // 用户数据
  {
    "id": 1,
    "name": "管理员",
    "role": "admin"
  },
  {
    "id": 2,
    "name": "普通用户",
    "role": "user"
  }
]
```

## 数据导入逻辑

### 导入流程

```
1. 读取文件 → 2. 解析数据 → 3. 验证格式 → 4. 分批处理 → 5. 导入数据库
```

### 文件类型识别

根据文件扩展名自动识别导入格式：

- `.csv` → CSV 格式
- `.xlsx`, `.xls` → Excel 格式
- `.json` → JSON 格式
- `.yao`, `.jsonc` → Yao (JSONC) 格式

### CSV/XLSX 处理流程

1. **读取文件**：从 `seed` 目录中读取文件内容
2. **解析表头**：读取第一行作为字段名
3. **构建类型映射**：根据模型定义分析每列的数据类型
4. **读取数据行**：逐行读取并转换为接口数组
5. **智能解析**：
   - JSON 类型字段：自动解析 JSON 字符串为对象
   - 布尔类型字段：转换 "true"/"false"/"1"/"0" 为布尔值
6. **分批处理**：按 `chunk_size` 分批处理数据
7. **导入数据库**：根据 `mode` 和 `duplicate` 策略导入

### JSON/Yao 处理流程

1. **读取文件**：从 `seed` 目录中读取文件内容
2. **解析数据**：使用标准 JSON 或 Yao 解析器解析
3. **提取字段**：从第一条记录提取所有字段名
4. **过滤字段**：
   - 只保留模型中存在的字段
   - 排除自动生成的字段（timestamps、trackings）
   - 按字母顺序排序以保证一致性
5. **分批处理**：按 `chunk_size` 分批处理数据
6. **导入数据库**：根据 `mode` 和 `duplicate` 策略导入

### 批量模式 (batch) 逻辑

- 使用 `Model.Insert` 批量插入数据
- 性能更高，适合大量数据导入
- 重复处理策略：
  - `ignore`：尝试插入，失败则忽略
  - `error`：插入失败则全部记录为失败
  - `update`/`abort`：自动降级为 each 模式处理

### 单条模式 (each) 逻辑

- 使用 `Model.Create` 或 `Model.Save` 逐条插入
- 支持更精细的错误处理
- 重复处理策略：
  - `ignore`：创建失败则忽略该条记录
  - `update`：检查记录是否存在，存在则更新，不存在则创建
  - `error`：创建失败则记录错误但继续
  - `abort`：创建失败则立即终止整个导入

## 字段类型处理

### JSON 字段

CSV/XLSX 中的 JSON 字段需要使用字符串格式，系统会自动解析：

```csv
id,name,settings
1,用户A,"{\"theme\":\"dark\",\"lang\":\"zh-CN\"}"
```

### 布尔字段

支持多种布尔值表示方式：

| 值                  | 结果  |
| ------------------- | ----- |
| true, TRUE, 1, yes  | true  |
| false, FALSE, 0, no | false |

### 自动生成的字段

以下字段会被自动排除，无需在数据文件中包含：

- `created_at`, `updated_at`, `deleted_at`（当 `timestamps` 启用时）
- `created_by`, `updated_by`, `deleted_by`（当 `trackings` 启用时）

## 导入结果

返回的 `ImportResult` 对象包含以下信息：

```javascript
{
  "total": 1000,      // 总记录数
  "success": 995,     // 成功导入数
  "failure": 3,       // 失败数
  "ignore": 2,        // 忽略数
  "errors": [         // 错误详情
    {
      "row": 10,
      "message": "duplicate key value violates unique constraint",
      "code": 500,
      "data": [...]
    }
  ]
}
```

## 最佳实践

### 1. 首次导入（Reset 场景）

```javascript
// 使用 update 策略，确保主键数据能正确创建
Process('seeds.import', 'initial_data.csv', 'user', {
  duplicate: 'update',
  mode: 'each'
});
```

### 2. 大数据量导入

```javascript
// 增大批量大小，使用 ignore 策略提高性能
Process('seeds.import', 'large_data.xlsx', 'log', {
  chunk_size: 2000,
  duplicate: 'ignore',
  mode: 'batch'
});
```

### 3. 数据更新

```javascript
// 使用 update 策略更新已有数据
Process('seeds.import', 'updates.json', 'product', {
  duplicate: 'update',
  mode: 'each'
});
```

### 4. 严格校验

```javascript
// 使用 abort 策略，遇到错误立即停止
Process('seeds.import', 'critical_data.csv', 'order', {
  duplicate: 'abort',
  mode: 'each'
});
```

## 常见问题

### 1. CSV 文件乱码

确保 CSV 文件使用 UTF-8 编码。

### 2. JSON 字段无法解析

检查 JSON 字符串是否正确转义引号：

- 正确：`"{\"key\":\"value\"}"`
- 错误：`'{"key":"value"}'`

### 3. Excel 导入失败

- 确保活动工作表包含数据
- 第一行必须是字段名称
- 文件不要过大，建议分批导入

### 4. 重复数据处理选择

- `ignore`：适合数据初始化，确保数据唯一性
- `update`：适合数据更新，保持最新状态
- `error`：适合需要完整错误报告的场景
- `abort`：适合要求数据严格一致性的场景

### 5. 空行处理

Excel 文件中的空行会被自动跳过，不会计入错误。

## 性能优化建议

1. **批量大小调整**：根据数据量调整 `chunk_size`
   - 小数据量（< 1000）：默认 500
   - 中等数据量（1000-10000）：1000-2000
   - 大数据量（> 10000）：2000-5000

2. **模式选择**：
   - 批量导入优先使用 `batch` 模式
   - 需要详细错误处理时使用 `each` 模式

3. **重复策略**：
   - 避免使用 `abort` 处理大量数据
   - 已知数据唯一时使用 `ignore` 提升性能

## 注意事项

1. 文件必须位于应用目录的 `seed` 目录中
2. CSV/XLSX 的表头必须与模型列名完全匹配
3. JSON/Yao 文件只包含模型中存在的字段
4. 主键字段如果存在，会用于识别重复记录
5. 导入操作不会自动创建模型，确保模型已定义
6. 大数据量导入时建议监控内存使用情况
